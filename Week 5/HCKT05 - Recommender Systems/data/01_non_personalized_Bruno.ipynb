{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "\n",
    "# Numpy, Pandas and Scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Model Evaluation\n",
    "from evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validate_sample_submission import validate_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv('BookRatings.csv')\n",
    "df_users = pd.read_csv('BooksUsers.csv')\n",
    "# df_books = pd.read_csv('BooksMetaInfo.csv')\n",
    "df_test = pd.read_csv('test_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = df_test.values.ravel().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-personalised recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_10_best(df_ratings):\n",
    "    '''Returns 10 ISBN numbers according to the following criteria:\n",
    "    - rated at least 80 times\n",
    "    - ranked according to average rating\n",
    "    '''\n",
    "    \n",
    "    # create ratings matrix\n",
    "    ratings_frame = df_ratings.set_index(['User-ID', 'ISBN']).unstack() # this is slow\n",
    "    ratings_frame.index.name = None\n",
    "    \n",
    "    # summarize\n",
    "    books_summary = pd.DataFrame(index=ratings_frame.columns)\n",
    "    books_summary['mean_rating'] = ratings_frame.mean(skipna=True)\n",
    "    books_summary['n_ratings'] = ratings_frame.count()\n",
    "    books_summary['highest_rating'] = ratings_frame.max()\n",
    "    books_summary['lowest_rating'] = ratings_frame.min()\n",
    "\n",
    "    # select\n",
    "    top_10 = books_summary[books_summary.n_ratings>=30]\\\n",
    "                    .sort_values('mean_rating', ascending=False)\\\n",
    "                    .head(10)\\\n",
    "                    .index.get_level_values('ISBN').tolist()\n",
    "    return top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = pick_10_best(df_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_non_personalized_submission(top_10, test_users):\n",
    "    \n",
    "    # sizes\n",
    "    n_users = len(test_users)\n",
    "    n_books = 10\n",
    "    \n",
    "    # output\n",
    "    recs = pd.DataFrame()\n",
    "    recs['User-ID'] = [user for user in test_users for book in range(n_books)]\n",
    "    recs['ISBN'] = top_10*n_users\n",
    "    # recs = recs.set_index('User-ID')\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pers_submission = generate_non_personalized_submission(top_10, test_users)\n",
    "\n",
    "if validate_submission(non_pers_submission):\n",
    "    non_pers_submission.to_csv('non_pers_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ratings(data: pd.DataFrame) -> csr_matrix:\n",
    "    \"\"\"Creates the ratings matrix of listening history with optional shape\n",
    "    \n",
    "    Creates the ratings matrix from the listening history imported using the read_users_history() method.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame):  Listening history for the users.\n",
    "        shape (tuple): The overall (n_users, n_items) shape desired for the matrix. \n",
    "                       If None, define the shape with the (n_users, n_items) from data argument.\n",
    "        \n",
    "    Returns:\n",
    "        ratings (csr_matrix): Ratings matrix with shape (n_users, n_items).\n",
    "    \n",
    "    \"\"\"\n",
    "    users, user_pos = np.unique(data.iloc[:, 0].values, return_inverse=True)\n",
    "    items, item_pos = np.unique(data.iloc[:, 1].values, return_inverse=True)\n",
    "    values = data.iloc[:, 2].fillna(0).values\n",
    "    \n",
    "    #R Matrix dimensions (n_users, n_items)\n",
    "    shape = (len(users), len(items))\n",
    "\n",
    "    R_ = csr_matrix((values, (user_pos, item_pos)), shape=shape)\n",
    "    return R_\n",
    "#ratings_user = make_ratings(df_ratings)\n",
    "#ratings_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the split we have 87,367 ratings in the train set and 21,842 ratings in the validation set.\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "\n",
    "def make_train_val_split(data: pd.DataFrame, test_size : float = 0.2):\n",
    "    \"\"\"Split the data into train and validation and returns the ratings matrixes accordingly.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Listening history for the users.\n",
    "        test_size (float): Percentage of listening history used for validation.\n",
    "    \n",
    "    Returns:\n",
    "        ratings_train (csr_matrix): Ratings matrix for train.\n",
    "        ratings_val (csr_matrix): Ratings matrix for validation.\n",
    "    \n",
    "    \"\"\"\n",
    "    train_data, val_data = train_test_split(data, test_size=test_size, random_state=8)\n",
    "\n",
    "    #Store the indexes of each observation to identify which records to replace with zero\n",
    "    train_index = train_data.index\n",
    "    val_index = val_data.index\n",
    "\n",
    "    #make copies of data to replace the observations\n",
    "    train_data_clean = data.copy()\n",
    "    val_data_clean = data.copy()\n",
    "\n",
    "    #Replace the validation observations on the training data\n",
    "    train_data_clean.loc[val_index,[\"Book-Rating\"]] = 0\n",
    "    \n",
    "    #Replace the training observations on the validation data\n",
    "    val_data_clean.loc[train_index,[\"Book-Rating\"]] = 0\n",
    "\n",
    "    #Create the R matrices\n",
    "    R_train = make_ratings(train_data_clean)\n",
    "    R_val = make_ratings(val_data_clean)\n",
    "\n",
    "    #remove the explicit zeros from the sparse matrices\n",
    "    R_train.eliminate_zeros()\n",
    "    R_val.eliminate_zeros()\n",
    "\n",
    "    return R_train, R_val\n",
    "\n",
    "ratings_train, ratings_val = make_train_val_split(df_ratings, test_size=test_size)\n",
    "print(f\"After the split we have {ratings_train.nnz:,} ratings in the train set and {ratings_val.nnz:,} ratings in the validation set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index for users which we have training data has length of 489.\n",
      "The index for users which we don't have training data has length of 100.\n"
     ]
    }
   ],
   "source": [
    "def get_indices_from_users_to_pred(users_to_pred: pd.DataFrame, data: pd.DataFrame):\n",
    "    \"\"\"Get the indices of users_to_pred for which we have data and for which we don't.\n",
    "    \n",
    "    Args:\n",
    "        users_to_pred (pd.DataFrame): DataFrame containing the list of users we are going to recommend items.\n",
    "        data (pd.DataFrame): Original of listening history for the users.\n",
    "        \n",
    "    Returns:\n",
    "        index_users_in_data (Int64Index): Index that filters the users_to_pred to get the user_id's with training data.\n",
    "        index_users_not_in_data (Int64Index): Index that filters the users_to_pred to get the user_id's without training data.\n",
    "        \n",
    "    \"\"\"\n",
    "    index_users_in_data = users_to_pred[users_to_pred.isin(data[\"User-ID\"].values).values].index\n",
    "    index_users_not_in_data = users_to_pred[~users_to_pred.isin(data[\"User-ID\"].values).values].index\n",
    "    \n",
    "    return index_users_in_data, index_users_not_in_data\n",
    "\n",
    "index_users_in_data, index_users_not_in_data = get_indices_from_users_to_pred(df_test, df_ratings)\n",
    "print(f\"The index for users which we have training data has length of {len(index_users_in_data)}.\")\n",
    "print(f\"The index for users which we don't have training data has length of {len(index_users_not_in_data)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings_user = df_ratings.iloc[index_users_in_data]\n",
    "#ratings_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5719x5719 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 759717 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_similarities(ratings_matrix, similarity_type):\n",
    "    \"\"\"\n",
    "    Get the cosine similarity between users.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings_matrix : csr_matrix\n",
    "              Ratings matrix.\n",
    "              \n",
    "    similarity_type: str, \"users\" or \"items\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    similarities : csr_matrixb\n",
    "                        sparse representation of the cosine similarity between users or items.\n",
    "    \"\"\"\n",
    "    if(similarity_type == \"users\"):\n",
    "        similarities = cosine_similarity(ratings_matrix, dense_output=False)\n",
    "    elif(similarity_type == \"items\"):\n",
    "        similarities = cosine_similarity(ratings_matrix.T, dense_output=False)\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "user_similarities = calculate_similarities(ratings_train,\"users\")\n",
    "user_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_users = df_ratings['User-ID'].unique().tolist()\n",
    "df_users = df_users[df_users['User-ID'].isin(training_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_data(df_users):\n",
    "    \n",
    "    # index\n",
    "    df_users = df_users.set_index('User-ID')\n",
    "    \n",
    "    # vectorize location data\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    user_profiles = vectorizer.fit_transform(df_users.Location)\n",
    "    \n",
    "    # join age information\n",
    "    user_similarities = cosine_similarity(user_profiles, dense_output=False)\n",
    "    \n",
    "    return user_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_loc_sim = process_user_data(df_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collab_filt_user_preds = make_user_predictions(user_loc_sim, ratings_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubelrennfix/.virtualenvs/blu12/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[       inf, 0.06666667,        nan, ...,        nan, 0.07142857,\n",
       "        0.11111111],\n",
       "       [0.06666667,        inf,        nan, ...,        nan, 0.03448276,\n",
       "        0.04166667],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.07142857, 0.03448276,        nan, ...,        nan,        inf,\n",
       "        0.2       ],\n",
       "       [0.11111111, 0.04166667,        nan, ...,        nan, 0.2       ,\n",
       "               inf]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(df_users.Age.values.reshape(-1,1) - df_users.Age.values.reshape(1,-1))**-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubelrennfix/.virtualenvs/blu12/lib/python3.6/site-packages/scipy/sparse/base.py:595: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.true_divide(self.todense(), other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<5719x47768 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30246008 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_user_predictions(S: csr_matrix, R_: csr_matrix):\n",
    "    \"\"\"Predict using collaborative filtering.\n",
    "    \n",
    "    Args:\n",
    "        S (csr_matrix): Similarities matrix (tipically using the cosine_similarity).\n",
    "        R_ (csr_matrix): Ratings matrix.\n",
    "        \n",
    "    Returns:\n",
    "        preds (csr_matrix): Predictions matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    weighted_sum = np.dot(S, R_)\n",
    "    \n",
    "    # We use the absolute value to support negative similarities.\n",
    "    # In this particular example there are none.\n",
    "    sum_of_weights = np.abs(S).sum(axis=1)\n",
    "    \n",
    "    preds = weighted_sum / sum_of_weights\n",
    "    \n",
    "    # Exclude previously rated items.\n",
    "    preds[R_.nonzero()] = 0\n",
    "    \n",
    "    return csr_matrix(preds)\n",
    "\n",
    "\n",
    "collab_filt_user_preds = make_user_predictions(user_similarities, ratings_train)\n",
    "collab_filt_user_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5209580173730646"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparsity(matrix: csr_matrix) -> float:\n",
    "    \"\"\"Calculates the sparsity of a matrix.\n",
    "    \n",
    "    Args:\n",
    "        matrix (csr_matrix): Sparse matrix.\n",
    "        \n",
    "    Returns:\n",
    "        sparsity_ (float): Sparsity percentage (between 0 and 1).\n",
    "    \n",
    "    \"\"\"\n",
    "    return 1 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])\n",
    "\n",
    "sparsity(collab_filt_user_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5791,  3950,  7192, ..., 17420, 25509,  7229],\n",
       "       [23964,  7192, 16034, ...,  1298, 16745, 17420],\n",
       "       [ 7192,  3950,  5791, ..., 19960, 32475, 17420],\n",
       "       ...,\n",
       "       [ 7192, 23964,  3950, ..., 16148, 12896, 16769],\n",
       "       [ 7192,  5791,  3950, ...,  8005, 16148,  8286],\n",
       "       [ 7192, 23964,  3950, ..., 13300,  5791, 16034]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_n(pred, n):\n",
    "    pred_ = np.negative(pred).toarray()\n",
    "    return pred_.argsort()[:, :n]\n",
    "\n",
    "\n",
    "collab_filt_most_rated = get_top_n(collab_filt_user_preds, 10)\n",
    "collab_filt_most_rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users to recommend books</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   users to recommend books\n",
       "0                        99\n",
       "1                       114\n",
       "2                       243\n",
       "3                       244\n",
       "4                       254"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store a Series with the unique user id's that we have in the original data.\n",
    "def get_unique_users(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get unique users in training data.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame):  listening history for the users.\n",
    "        \n",
    "    Returns:\n",
    "        unique_users (pd.DataFrame): DataFrame of one column with unique users in training data.\n",
    "    \n",
    "    \"\"\"\n",
    "    return pd.DataFrame(np.unique(data.iloc[:, 0].values), columns=[\"users to recommend books\"])\n",
    "\n",
    "\n",
    "unique_users_training_data = get_unique_users(df_ratings)\n",
    "unique_users_training_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>users to recommend books</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5791</td>\n",
       "      <td>3950</td>\n",
       "      <td>7192</td>\n",
       "      <td>7835</td>\n",
       "      <td>23964</td>\n",
       "      <td>23963</td>\n",
       "      <td>1354</td>\n",
       "      <td>17420</td>\n",
       "      <td>25509</td>\n",
       "      <td>7229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>23964</td>\n",
       "      <td>7192</td>\n",
       "      <td>16034</td>\n",
       "      <td>16148</td>\n",
       "      <td>5791</td>\n",
       "      <td>3950</td>\n",
       "      <td>32475</td>\n",
       "      <td>1298</td>\n",
       "      <td>16745</td>\n",
       "      <td>17420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>7192</td>\n",
       "      <td>3950</td>\n",
       "      <td>5791</td>\n",
       "      <td>23964</td>\n",
       "      <td>25296</td>\n",
       "      <td>16148</td>\n",
       "      <td>25509</td>\n",
       "      <td>19960</td>\n",
       "      <td>32475</td>\n",
       "      <td>17420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>7192</td>\n",
       "      <td>23964</td>\n",
       "      <td>3950</td>\n",
       "      <td>22610</td>\n",
       "      <td>16148</td>\n",
       "      <td>8286</td>\n",
       "      <td>5791</td>\n",
       "      <td>16034</td>\n",
       "      <td>25509</td>\n",
       "      <td>16425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>7192</td>\n",
       "      <td>5791</td>\n",
       "      <td>7229</td>\n",
       "      <td>16148</td>\n",
       "      <td>25509</td>\n",
       "      <td>23964</td>\n",
       "      <td>32475</td>\n",
       "      <td>25296</td>\n",
       "      <td>869</td>\n",
       "      <td>11742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0      1      2      3      4      5      6  \\\n",
       "users to recommend books                                                    \n",
       "99                         5791   3950   7192   7835  23964  23963   1354   \n",
       "114                       23964   7192  16034  16148   5791   3950  32475   \n",
       "243                        7192   3950   5791  23964  25296  16148  25509   \n",
       "244                        7192  23964   3950  22610  16148   8286   5791   \n",
       "254                        7192   5791   7229  16148  25509  23964  32475   \n",
       "\n",
       "                              7      8      9  \n",
       "users to recommend books                       \n",
       "99                        17420  25509   7229  \n",
       "114                        1298  16745  17420  \n",
       "243                       19960  32475  17420  \n",
       "244                       16034  25509  16425  \n",
       "254                       25296    869  11742  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_pers_recommendations_to_df(pers_recs: np.array, users_to_pred: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Converts the personalized most rated to an DataFrame with the users and the recommendations.\n",
    "    \n",
    "    Args:\n",
    "        pers_recs (np.array): Array of indices for the best personalized items to recommend.\n",
    "        users_to_pred (pd.DataFrame): DataFrame containing the users which need recommendations.\n",
    "        \n",
    "    Returns:\n",
    "        non_pers_most_rated_matrix (np.array): Two dimensional array of (n_users, top_n_items)\n",
    "    \n",
    "    \"\"\"\n",
    "    pers_df = pd.concat([users_to_pred, pd.DataFrame(pers_recs)], axis=1)\n",
    "    pers_df = pers_df.set_index(\"users to recommend books\")\n",
    "    \n",
    "    return pers_df\n",
    "\n",
    "\n",
    "collab_filt_most_rated_df = convert_pers_recommendations_to_df(collab_filt_most_rated, unique_users_training_data)\n",
    "collab_filt_most_rated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{99: [5791, 3950, 7192, 7835, 23964, 23963, 1354, 17420, 25509, 7229]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_dict_preds(preds_df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Convert the predictions DataFrame (index:users -> columns: items) to a dictionary of key (user->list of items).\n",
    "    \n",
    "    Args: \n",
    "        preds_df (pd.DataFrame): DataFrame containing the users and the ordered predictions.\n",
    "        \n",
    "    Returns:\n",
    "        preds_dict (dict): Dict of (user_id: list of items) used for evaluating the performance.\n",
    "    \n",
    "    \"\"\"\n",
    "    return {preds_df.index[i]: preds_df.values[i].tolist() for i in range(len(preds_df))}\n",
    "\n",
    "\n",
    "collab_filt_dict = create_dict_preds(collab_filt_most_rated_df)\n",
    "# Since dicts in python are not ordered, we need to HAMMER DOWN a way to print some values.\n",
    "dict(list(collab_filt_dict.items())[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006104803814630708"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_y_true(R_val_: csr_matrix, users_to_pred: pd.DataFrame, n=100):\n",
    "    \"\"\"Get the ground truth (best recommendations) of the users in the validation set.\n",
    "    \n",
    "    Args:\n",
    "        R_val_ (csr_matrix): Validation set ratings matrix.\n",
    "        users_to_pred: \n",
    "        n (int): Number of top-n items.\n",
    "        \n",
    "    Returns:\n",
    "        y_true_df (pd.DataFrame): DataFrame which returns the y_true items.\n",
    "        \n",
    "    \"\"\"\n",
    "    top_from_R_val = pd.DataFrame(np.negative(R_val_).toarray().argsort()[:, :n])\n",
    "    y_true_df = pd.concat([users_to_pred, top_from_R_val], axis=1)\n",
    "    y_true_df = y_true_df.set_index(\"users to recommend books\")\n",
    "    return y_true_df\n",
    "\n",
    "\n",
    "y_true_df = get_y_true(ratings_val, unique_users_training_data, n=10)\n",
    "y_true_dict = create_dict_preds(y_true_df)\n",
    "\n",
    "evaluate(y_true_dict, collab_filt_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_item_predictions(S, R):\n",
    "    \n",
    "    weighted_sum = np.dot(R, S)\n",
    "    \n",
    "    # We use the absolute value to support negative similarities.\n",
    "    # In this particular example there are none.\n",
    "    sum_of_weights = np.abs(S).sum(axis=0)\n",
    "    \n",
    "    preds = weighted_sum / sum_of_weights\n",
    "    \n",
    "    # Exclude previously rated items.\n",
    "    preds[R.nonzero()] = 0\n",
    "    \n",
    "    return csr_matrix(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_recs = pd.read_csv('content_based.csv')\\\n",
    "                    .rename(columns={'Unnamed: 0': 'User-ID'})\\\n",
    "                    .set_index('User-ID')\\\n",
    "                    .stack()\\\n",
    "                    .reset_index()\\\n",
    "                    .drop(columns='level_1')\\\n",
    "                    .rename(columns={0: 'ISBN'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>0786015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>1881554031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>1592231365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>1584792965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>0812014790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>278633</td>\n",
       "      <td>087406452X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>278633</td>\n",
       "      <td>0440402255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>278633</td>\n",
       "      <td>0966533356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>278633</td>\n",
       "      <td>051754489X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>278633</td>\n",
       "      <td>0380708353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User-ID        ISBN\n",
       "0         114  0786015810\n",
       "1         114  1881554031\n",
       "2         114  1592231365\n",
       "3         114  1584792965\n",
       "4         114  0812014790\n",
       "...       ...         ...\n",
       "4885   278633  087406452X\n",
       "4886   278633  0440402255\n",
       "4887   278633  0966533356\n",
       "4888   278633  051754489X\n",
       "4889   278633  0380708353\n",
       "\n",
       "[4890 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_submission = merge_submissions(non_pers_submission, content_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_submission(content_submission):\n",
    "    content_submission.to_csv('content_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_submission(collab_filt_most_rated, df_ratings, test_users):\n",
    "    \n",
    "    # indices\n",
    "    ratings_frame = df_ratings.set_index(['User-ID', 'ISBN']).unstack()\n",
    "    users = ratings_frame.index.tolist()\n",
    "    books = ratings_frame.columns.get_level_values(1).tolist()\n",
    "    \n",
    "    # replace values\n",
    "    recs = pd.DataFrame(collab_filt_most_rated, index=users).stack()\n",
    "    col_to_isbn = {i: isbn for i, isbn in enumerate(books)}\n",
    "    recs = recs.replace(col_to_isbn)\n",
    "    \n",
    "    # filter\n",
    "    recs.index = recs.index.get_level_values(0).tolist()\n",
    "    recs = recs[recs.index.isin(test_users)]\n",
    "\n",
    "    # format frame\n",
    "    recs = recs.reset_index()\n",
    "    recs.columns = ['User-ID', 'ISBN']\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_submission = produce_submission(collab_filt_most_rated, df_ratings, test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_submissions(non_pers_submission, pers_submission):\n",
    "    \n",
    "    combined_submission = pers_submission\\\n",
    "                                .append(non_pers_submission[~non_pers_submission['User-ID']\\\n",
    "                                                            .isin(pers_submission['User-ID'])])\\\n",
    "                                .sort_values('User-ID')\n",
    "\n",
    "    return combined_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_submission = merge_submissions(non_pers_submission, pers_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if validate_submission(merged_submission):\n",
    "    merged_submission.to_csv('combined_submission_locations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rubelrennfix/.virtualenvs/blu12/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pers_submission['ISBN'].values == merged_submission['ISBN'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>0312995423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>043935806X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>0066214122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>0671027387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114</td>\n",
       "      <td>0312195516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>278633</td>\n",
       "      <td>0140293248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>278633</td>\n",
       "      <td>0804114986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>278633</td>\n",
       "      <td>0345361792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>278633</td>\n",
       "      <td>0316284955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4889</th>\n",
       "      <td>278633</td>\n",
       "      <td>0446532231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User-ID        ISBN\n",
       "0         114  0312995423\n",
       "1         114  043935806X\n",
       "2         114  0066214122\n",
       "3         114  0671027387\n",
       "4         114  0312195516\n",
       "...       ...         ...\n",
       "4885   278633  0140293248\n",
       "4886   278633  0804114986\n",
       "4887   278633  0345361792\n",
       "4888   278633  0316284955\n",
       "4889   278633  0446532231\n",
       "\n",
       "[5890 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_submission#['ISBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
